{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "import netron\n",
    "from keras.models import load_model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the header list\n",
    "header_list = [\"Frame\",\"Face\",\"keypoint\",\"Body\",\"1_x\",\"1_y\",\"1_accuracy\",\"2_x\",\"2_y\",\"2_accuracy\",\"3_x\",\"3_y\",\"3_accuracy\",\"4_x\",\"4_y\",\"4_accuracy\",\"5_x\",\"5_y\",\"5_accuracy\",\"6_x\",\"6_y\",\"6_accuracy\",\"7_x\",\"7_y\",\"7_accuracy\",\"8_x\",\"8_y\",\"8_accuracy\",\"9_x\",\"9_y\",\"9_accuracy\",\n",
    "               \"10_x\",\"10_y\",\"10_accuracy\",\"11_x\",\"11_y\",\"11_accuracy\",\"12_x\",\"12_y\",\"12_accuracy\",\"13_x\",\"13_y\",\"13_accuracy\",\"14_x\",\"14_y\",\"14_accuracy\",\"15_x\",\"15_y\",\"15_accuracy\",\"16_x\",\"16_y\",\"16_accuracy\",\"17_x\",\"17_y\",\"17_accuracy\",\"18_x\",\"18_y\",\"18_accuracy\",\"19_x\",\"19_y\",\"19_accuracy\",\n",
    "               \"20_x\",\"20_y\",\"20_accuracy\",\"21_x\",\"21_y\",\"21_accuracy\",\"22_x\",\"22_y\",\"22_accuracy\",\"23_x\",\"23_y\",\"23_accuracy\",\"24_x\",\"24_y\",\"24_accuracy\",\"25_x\",\"25_y\",\"25_accuracy\"]\n",
    "\n",
    "df = pd.read_csv('C:/Users/CASALAB/Desktop/progetto_CASA/merged_json_csv.csv', names=header_list)\n",
    "#set lists with frame data extracted with dlib and openpose\n",
    "frame=df['Frame']\n",
    "face=df['Face']\n",
    "body=df['Body']\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Converting string labels into numbers.\n",
    "face_encoded=le.fit_transform(face)\n",
    "body_encoded=le.fit_transform(body)\n",
    "\n",
    "print (\"Frame:\", frame)\n",
    "print (\"Face:\", face_encoded)\n",
    "print(\"Body:\", body_encoded)\n",
    "\n",
    "#create the list with images\n",
    "train_image = []\n",
    "for i in tqdm(range(frame.shape[0])):\n",
    "    img = image.load_img('C:/Users/CASALAB/Desktop/progetto_CASA/codice/prova3/'+frame[i][:6]+'/'+frame[i][-4:]+'.jpg',target_size=(150,150,3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    train_image.append(img)\n",
    "X = np.array(train_image)\n",
    "X.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to print the accuracy\n",
    "def print_acc(hist):\n",
    "    epochs = range(1, len(hist['accuracy'])+1)\n",
    "    plt.plot(epochs, hist['accuracy'], 'b', label='Training acc')    \n",
    "    plt.plot(epochs, hist['val_accuracy'], 'r', label='Validation acc')\n",
    "    plt.title('Training and validation acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Acc')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to print the loss\n",
    "def print_loss(hist):\n",
    "    epochs = range(1, len(hist['loss'])+1)\n",
    "    plt.plot(epochs, hist['loss'], 'b', label='Training loss')\n",
    "    plt.plot(epochs, hist['val_loss'], 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the y variable containing features\n",
    "features=list(zip(face_encoded,body_encoded))\n",
    "y=np.array(features)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split label and feature into two array containing training(80%) and validation(20%) data\n",
    "train_pct_index = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_pct_index], X[train_pct_index:]\n",
    "y_train, y_test = y[:train_pct_index], y[train_pct_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train , y_train = shuffle ( X_train , y_train , random_state =0)\n",
    "X_test , y_test = shuffle ( X_test , y_test , random_state =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model layer\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), activation=\"relu\", input_shape=(150,150,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model and print a resume\n",
    "model.save('Modello.hdf5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start netron software\n",
    "netron.start('Modello.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model with optimizer and loss function\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#training the model with training set and validate with validation set\n",
    "dense_hist = model.fit(X_train, y_train, epochs=25, validation_data=(X_test, y_test), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the trained model\n",
    "model.save('ModelloAllenato.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trainHistoryDict', 'wb') as file_pi:\n",
    "        pickle.dump(dense_hist, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the train story\n",
    "history = pickle.load(open('trainHistoryDict', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_hist = dense_hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the accuracy\n",
    "print_acc(dense_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the loss\n",
    "print_loss(dense_hist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
